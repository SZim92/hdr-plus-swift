name: Performance Benchmarks

on:
  workflow_dispatch:
    inputs:
      create_baseline:
        description: 'Create new performance baseline'
        type: boolean
        default: false
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - '**.swift'
      - 'Package.swift'
      - '.github/workflows/performance-benchmarks.yml'
  push:
    branches:
      - main
    paths:
      - '**.swift'
      - 'Package.swift'
      - '.github/workflows/performance-benchmarks.yml'
  schedule:
    - cron: '0 3 * * 1'  # Run at 3 AM UTC every Monday

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  config:
    name: Load Configuration
    runs-on: ubuntu-22.04
    outputs:
      regression-threshold: ${{ steps.load-config.outputs.max-perf-regression || '5' }}
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
      
      - name: Load configuration
        id: load-config
        uses: ./.github/actions/load-config

  run-benchmarks:
    name: Run Performance Benchmarks
    needs: config
    runs-on: macos-latest
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better context
      
      - name: Set up Swift environment
        uses: ./.github/actions/setup-swift
        with:
          xcode-version: latest
      
      - name: Set up build cache
        uses: ./.github/actions/build-cache
      
      - name: Download baseline
        id: download-baseline
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: benchmark-baseline
          path: benchmark-results
      
      - name: Run benchmarks
        id: benchmarks
        uses: ./.github/actions/run-benchmarks
        with:
          compare-with-baseline: true
          create-baseline: ${{ github.event.inputs.create_baseline == 'true' || github.event_name == 'schedule' }}
          regression-threshold: ${{ needs.config.outputs.regression-threshold }}
      
      - name: Create baseline if needed
        if: github.event.inputs.create_baseline == 'true' || github.event_name == 'schedule'
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-baseline
          path: benchmark-results/baseline.json
          retention-days: 90
      
      - name: Check for regressions
        if: steps.benchmarks.outputs.has-regression == 'true'
        run: |
          echo "::warning::${{ steps.benchmarks.outputs.regression-details }}"
          
          # Exit with non-zero status for scheduled runs to mark the workflow as failed
          # This ensures the team is alerted to performance regressions
          if [ "${{ github.event_name }}" == "schedule" ]; then
            echo "Failing workflow due to performance regression on scheduled run"
            exit 1
          fi
      
      - name: Upload performance report to summary
        run: |
          cat benchmark-results/latest_report.md >> $GITHUB_STEP_SUMMARY
      
      - name: Comment on PR
        if: github.event_name == 'pull_request' && steps.benchmarks.outputs.has-regression == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const reportContent = fs.readFileSync('benchmark-results/latest_report.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `# âš ï¸ Performance Regression Detected\n\n${reportContent}\n\nPlease review these performance changes before merging.`
            });

  benchmark-history:
    name: Update Benchmark History
    needs: run-benchmarks
    if: success() && github.event_name != 'pull_request'
    runs-on: ubuntu-latest
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
      
      - name: Download benchmark results
        uses: actions/download-artifact@v4
        with:
          name: performance-benchmarks
          path: benchmark-results
      
      - name: Generate benchmark history
        run: |
          # Create history directory if it doesn't exist
          mkdir -p benchmark-history
          
          # Get the latest result file
          LATEST_RESULT=$(ls -t benchmark-results/benchmark_*.json | head -1)
          
          if [ -n "$LATEST_RESULT" ]; then
            # Extract timestamp from filename
            TIMESTAMP=$(echo $LATEST_RESULT | sed -E 's/.*benchmark_([0-9_]+)\.json/\1/')
            
            # Copy the result to history with date-based naming
            cp $LATEST_RESULT benchmark-history/
            
            # Create or update history log
            if [ ! -f benchmark-history/history.csv ]; then
              echo "date,average_runtime" > benchmark-history/history.csv
            fi
            
            # Extract average runtime and add to CSV
            AVERAGE=$(jq '.benchmarks | map(.time) | add / length' $LATEST_RESULT)
            echo "$TIMESTAMP,$AVERAGE" >> benchmark-history/history.csv
            
            # Generate visualization using simple ASCII chart
            echo "## Benchmark History" > benchmark-history/history.md
            echo "" >> benchmark-history/history.md
            echo "Last 10 runs:" >> benchmark-history/history.md
            echo '```' >> benchmark-history/history.md
            
            # Use tail to get last 10 entries and format as ASCII chart
            tail -n 10 benchmark-history/history.csv | awk -F',' 'NR>1 {printf "%-16s %8.3f s  ", $1, $2; for(i=0;i<$2*10;i++) printf "#"; print ""}' >> benchmark-history/history.md
            
            echo '```' >> benchmark-history/history.md
          else
            echo "No benchmark results found"
          fi
      
      - name: Upload benchmark history
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-history
          path: benchmark-history/
          retention-days: 90
      
      - name: Add history to summary
        run: |
          if [ -f benchmark-history/history.md ]; then
            cat benchmark-history/history.md >> $GITHUB_STEP_SUMMARY
          fi

  notify-regression:
    name: Notify about Performance Regression
    needs: [config, run-benchmarks]
    if: failure() && github.event_name == 'schedule'
    runs-on: ubuntu-latest
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
      
      - name: Download benchmark results
        id: download-results
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: performance-benchmarks
          path: benchmark-results
      
      - name: Create issue for performance regression
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            let body = '# ðŸš¨ Performance Regression Detected\n\n';
            
            try {
              if (fs.existsSync('benchmark-results/latest_report.md')) {
                body += fs.readFileSync('benchmark-results/latest_report.md', 'utf8');
              } else {
                body += 'Performance regression detected in scheduled benchmark run, but detailed report is not available.\n';
              }
            } catch (error) {
              body += 'Error retrieving benchmark report: ' + error.message;
            }
            
            body += '\n\n## Action Items\n\n';
            body += '1. Review recent code changes that might have affected performance\n';
            body += '2. Consider optimizing the affected code paths\n';
            body += '3. If the regression is acceptable, update the performance baseline\n';
            
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ðŸš¨ Performance Regression Detected in Scheduled Benchmark',
              body: body,
              labels: ['performance', 'regression', 'priority-high']
            });
      
      - name: Send notification
        uses: ./.github/actions/notify-slack
        with:
          webhook-url: ${{ secrets.SLACK_WEBHOOK_URL }}
          channel: ci-alerts
          status: failure
          title: "Performance Regression Detected"
          message: "A performance regression was detected in the scheduled benchmark run. Please check the GitHub issue for details."
          footer: "Performance Benchmarks | Triggered by scheduled run" 